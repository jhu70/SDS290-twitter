---
title: "Group Twitter: Technical Report"
author: "Jocelyn Hu, Natalie Labossier,Caroline Li"
date: "April 30, 2019"
output:
  html_document:
    highlight: tango
    theme: cosmo
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: true
    df_print: kable
---


#Abstract


#Introduction

We are trying to increase the engagement on the Smith College Executive Education Office twitter page. Specifically, we want to explore what kinds of content and ways of presenting content could increase the number of likes and retweets. More likes and retweets are important for the publicity of the center, which may eventually lead to more engagement in the center’s programming.

We intend to explore the following questions: What type of tweets get the most engagement? What type of tweets are most retweeted? What type of tweets receives the most likes? What time of day is optimal for post engagement?

We hypothesized that tweets that are inspirational will have the most retweets because followers may believe that they are the most interesting to their own twitter followers. We also hypothesized that promotional posts will have the lowest engagement. We hypothesized that posts in the morning (8:30am) will have more engagement because people may be commuting at that time, and those tweets may remain visible during the work day and lunch hour. We wanted to explore if the interaction effect (Content X TimeofDay) exists.


#Method

This study is a Latin Square design. The two factors of interest, type of post and time of posting, are crossed. 

We use 9 original posts. Each post will be posted twice, once at 8:30am and once at 4:30pm on the same day, making time slot a within block factor.

We design the Latin square by creating week layouts and randomly assigning each of the layouts to one of the three weeks of our study. We then randomly assign post type (treatment) to each of the three letters (A, B, and C). After that, the interns at the office add each post on twitter based on the pre-decided schedule. 

--------------------------------------------------------------------------------------------------------------
![](schedule.png){width=100% } 
A= inspirational morning post a = inspirational afternoon post; 
B= informative morning post b = informative afternoon post; 
C= promotional morning post c = promotional afternoon post

--------------------------------------------------------------------------------------------------------------




The next step is to add up the number of likes and retweets 48 hours later to measure readers’ level of engagement. The time period after which engagement is measured is constant among the posts.

After wrapping up the experiment, we calculate the averages to compare the overall difference between types of posts, day of week, and time of day. 

The Executive Education Assistants created the content in advance of the study, and they contacted Jill directly for approval. 

A preview of the posts could be found in the appendix.

#Results

##Summary statistics

```{r,echo=FALSE, warning=FALSE, message=FALSE, include = FALSE}
library(dplyr)
library(mosaic)
library(ggplot2)
library(readr)
library(tidyr)
library(tidyverse)
```

```{r,echo=FALSE, warning=FALSE, message=FALSE, include = FALSE}
df <- read_csv("data_twitter - Sheet2.csv")
```

```{r,echo=FALSE, warning=FALSE, message=FALSE, include = FALSE}
day <- c("Wed","Wed","Thurs","Thurs","Fri","Fri","Wed","Wed","Thurs","Thurs","Fri","Fri","Wed","Wed","Thurs","Thurs","Fri","Fri")
week <- c(rep("1", 6),                                  rep("2",6), rep("3",6))
df<-cbind(day,df)
df<-cbind(week,df)

```

```{r sum_engage,echo=FALSE, warning=FALSE, message=FALSE, include = FALSE}
df<-df%>%
  mutate(sum_engage=likes_48+retweets_48+comments_48)%>%
  unite(cell, time, type,remove=FALSE)

```

```{r,echo=FALSE, warning=FALSE, message=FALSE, include = FALSE}
library(tidyverse)
df2<-as.data.frame(df)%>%
  na.omit()%>%
  select(sum_engage,likes_48,retweets_48,comments_48,type)
```

```{r,echo=FALSE, warning=FALSE, message=FALSE, include = FALSE}
library(stargazer)
stargazer(data = df2, type = "html", title="Summary statistics of DV", digits=2, out="tablesum.html",covariate.labels = c("Total Engagement","#Likes","#Retweets","#Comments","type"))

```

```{r, out.width='70%', fig.align='center', include = TRUE, echo = FALSE}
knitr::include_graphics('sum.png')
```

According to the summary statistics table, we only collect 18 observations in total and the amount of engagement might be too small to be informative and statistically meaningful. The mean amount of engagement is less than one (mean = 0.78)



 

### Testing Assumptions - Assembly Line Metaphor

#### Assembly Line Instructions

Before analyzing the results, we first calculate the effects of all of our structural factors under the Fisher assumptions. The chunks of code below calculate all of the peices we'll need in our assembly line. Each chunk is a station. The Fisher assumptions are built into the way we are calculating our assembly line instructions and when simulating the data below. The six Fisher assumptions we test include constant effects(C), additive effects(A), same standard deviations (S), independent residuals (I), normally distributed residuals (N), and zero mean residuals (Z).

Based on the discussions below, only the third assumption, S, is not violated.

#####Constant 


```{r}
df <- df%>%
  mutate(benchmark = mean(sum_engage)) #universal factor
```

```{r}
df <- df %>%
  group_by(type) %>%
  mutate(type_mean = mean(sum_engage),
         type_effect = type_mean - benchmark) 
#for each level of type factor
print(df$type_effect)
```

```{r}
df <- df %>%
  group_by(week) %>%
  mutate(week_mean = mean(sum_engage),
         week_effect = week_mean - benchmark) 
#for each level of type factor
print(df$week_effect)
```

```{r}
df <- df %>%
  group_by(day) %>%
  mutate(day_mean = mean(sum_engage),
         day_effect = day_mean - benchmark) 
#for each level of type factor
print(df$day_effect)
```

```{r}
df <- df %>%
  group_by(time) %>%
  mutate(time_mean = mean(sum_engage),
         time_effect = time_mean - benchmark) 
#for each level of type factor
print(df$time_effect)
```

```{r}
df <- df %>%
  group_by(cell) %>%
  mutate(cell_mean = mean(sum_engage),
         interaction_effect = cell_mean - (type_mean + time_mean - benchmark)) #for each cell of interaction
print(df$interaction_effect)
```

From above, we could see that the assumption of constant effects is violated since not very observation in a similar condition is affected exactly the same. The week, day of week, type, and interaction effects are not constant.

```{r}
df<- df %>%
  ungroup() %>%
  mutate(residuals = sum_engage - (benchmark 
                             + type_effect 
                             + time_effect 
                             + interaction_effect
                             + day_effect
                             + week_effect)
                             )%>% #universal factor
  select(-type_mean, -time_mean, 
         -cell_mean, -day_mean, -week_mean) #removing the stuff we don't need


```

S: There should be one standard deviation for all the errors, so the peice of code for adding error is not dependent on which condition the observations is in. We consider this assumption violated if the SD of the biggest group is more than three times as big as the SD of the smallest group. Acccording to the summary statistics table, SDmax = 0.78 < 3*SDmin = 0.24, so this assumption is not violated. 

I: To check for independence in my residuals if I have a within block treatment factor that has two levels, we should be looking for the points to fall along the y =x when making a scatterplot of observations for two levels of a within-block factor. In this case, we will test the assumption by plotting residuals against a time variables present (e.g., order of observation). A pattern that is not random suggests lack of independence. There is no observable pattern so the Independence assumption is not violated.


```{r}
library(dae)

df<-df%>%
 mutate(order = 1:18)

ggplot(df, aes(x = order, y = residuals)) + 
  geom_point() +
  geom_hline(yintercept = 0, color = "red")

# ggplot(df2, aes(x = fitted(twitter), y = residuals(twitter))) + 
#   geom_point() +
#   geom_hline(yintercept = 0, color = "red")
```

N: The distribution of error sizes should follow a normal curve. According to the histogram below, this assumption is violated since the histogram is right-skewed. 

```{r}
ggplot(df, aes(x = residuals)) +
    geom_histogram()
```


Z: The average of the tickets in the errpr box should be zero. As shown below, the mean residual is not zero but is really really close to zero so this assumption roughly holds.

```{r}
df$meanred<-mean(df$residuals)
print(df$meanred)
```


```{r simulation}
df<- df %>%
  mutate(engage_sim = NA)

df<- df %>%
  mutate(engage_sim = benchmark 
                             + type_effect 
                             + time_effect 
                             + interaction_effect
                             + day_effect
                             + week_effect
                             + rnorm(12, 0, 0.65)) 
```

A: The pieces that go together to make the observed value should be combined by adding them, so we add the effects as we go down the assembly line. The interaction effect captures the possibility that conditions have non-additive effects, but it is also added to everything else. 

Below we visualize the simulated data and compare the results with the visualizations of the actual data. As shown, the additive assumption seems to be violated since the simulated results are very different. 

##### Parallel dot graph

Real data:
```{r}
ggplot(df, aes(x = type, color = time, y = sum_engage)) +
    geom_jitter(height = 0.10, width = 0.05, alpha = .7)
```

Simulated:
```{r}
ggplot(df, aes(x = type, color = time, y = engage_sim)) +
    geom_jitter(height = 0.10, width = 0.05, alpha = .7)
```

##### Side-by-side Boxplots


Real data:

```{r,echo=FALSE, warning=FALSE, message=FALSE, include = TRUE}
#looking at variability by condition
ggplot(df, aes(x = type, fill = time, y = sum_engage)) +
  geom_boxplot()

```

Simulated:
```{r}
ggplot(df, aes(x = type, fill = time, y = engage_sim)) +
  geom_boxplot()
```



##Interaction effects
Read data:
```{r echo=FALSE, warning=FALSE, message=FALSE, include = TRUE}
ggplot(df, aes(x = time, 
                    y = sum_engage, 
                    color = type,
                    group = type)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = 0)
```

Simulated:
```{r}
ggplot(df, aes(x = type, 
                    y = engage_sim, 
                    color = time,
                    group = time)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = 0)
```
`


##Informal Analysis

Before conducting a formal analysis, we arrange a side by side boxplot and an interaction graph towith the categories either on the horizontal axis of the display to allow comparising between the different categories as well as comparison within categories.

###Side by side boxplot

```{r,echo=FALSE, warning=FALSE, message=FALSE, include = TRUE}
#looking at variability by condition
ggplot(df, aes(x = type, fill = time, y = sum_engage)) +
  geom_boxplot()

```

The side by side boxpot above tells us that there may be a main effect of time of day (morning posts seem to get more engagement than afternoon posts), and a main effect of post content (promotional posts get less engagement than informative and inspirational posts).

###Parallel dot plot

```{r}
ggplot(df, aes(x = type, color = time, y = sum_engage)) +
    geom_jitter(height = 0.10, width = 0.05, alpha = .7)
```


##Interaction effects

The interaction graph indicates that first, there may be an interaction between type and time when the promotional type is included sinc the line of promotional posts is not parallel with the other two lines. Second, there is no interaction between type and time when the promotional type is excluded since the line of inspirational posts an the line of informative posts are parallel with each other. Third, there is a main effect of time of the day since the lines of inspirational and informative posts are upward sloping.

```{r echo=FALSE, warning=FALSE, message=FALSE, include = TRUE}
ggplot(df, aes(x = time, 
                    y = sum_engage, 
                    color = type,
                    group = type)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = 0)
```


##ANOVA

To look more deeply into the impacts of these variables on the amount of people's engagement on twitter, we conduct the analysis of variance to decide if the effects of these variables are real. Since our assumptions about residuals (Same SD and Normally Distributed Residuals) are violated by the promotional group, We  excluded this group from our formal ANOVA.


```{r,echo=FALSE, warning=FALSE, message=FALSE, include = FALSE}
df2<-df%>%
  filter(type =="informative"| type =="inspirational")
```

```{r,echo=FALSE, warning=FALSE, message=FALSE, include = TRUE}
twitter <- aov(sum_engage ~ type+time+day+week+type*time, data = df2)

anova1<-anova(twitter)
summary(twitter)

#favstats(sum_engage~type|time, data = df2)

# library(mosaic)
# tally(~time|as.character(type), data = df2)
# 
# df2$type
```



```{r,echo=FALSE, warning=FALSE, message=FALSE, include = FALSE}
is.num <- sapply(anova1, is.numeric)
anova1[is.num] <- lapply(anova1[is.num], round, 3)
anova1[4,5]<-"0.250"
anova1[1,5]<-"0.230"
anova1[1,6]<-""
anova1[2,6]<-"*"
anova1[3,6]<-"*"
anova1[4,6]<-" "
anova1[5,6]<-" "
anova1[6,6]<-" "
anova1[6,5]<-" "
anova1[6,4]<-" "
anova2<-anova1[1:6,]

```

```{r,echo=FALSE, warning=FALSE, message=FALSE, include =TRUE}
library(kableExtra)
kable(anova2, digits = 3, format = "html", booktabs = T,col.names = c("Df","Sum Sq","Mean Sq","F value"," Pr(>F)"," "))%>%
  kable_styling(full_width = F, font_size = 12)%>%add_footnote("Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1", notation="alphabet")%>%column_spec(1, width = "5em") 
```




Excluding promotional posts, we could see from the table above that there is not a significant main effect of post type. Interaction between type and time was not significant as well. However, time of posting is significantly associated with engagement. Specifically, morning posts obtain more engagements than afternoon posts. 

In a word, the parallel box-plot and ANOVA indicate the statistically significant main effects of time of day (p=0.047). Excluding promotional posts, there is not a significant main effect of post type (p=0.23). The interaction graph and ANOVA table (excluding promotional posts) indicate the interaction effect of type and time is not statistically significant (p=1).  



#Conclusion

#Appendix



![April 3rd- Informative](posts/p1.jpg){ width=40% }




![April 4th- Promotional](posts/p2.jpg){ width=40% }



![April 5th- Inspirational](posts/p3.jpg){ width=40% }



![April 10th- Inspirational](posts/p4.jpg){ width=40% }



![April 11th- Informative](posts/p5.jpg){ width=40% }


![April 12th- Promotional](posts/p6.jpg){ width=40% }



![April 17th- Promotional](posts/p7.jpg){ width=40% }

![April 18th- Inspirational](posts/p8.jpg){ width=40% }


![April 19th- Informative](posts/p9.jpg){ width=40% }
